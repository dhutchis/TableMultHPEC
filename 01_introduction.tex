%!TEX root =SpGEMM_ACCUMULO_HPEC.tex

\section{Introduction}
\label{sIntro}
% 

%Accumulo is well-known as a high performance NoSQL database with respect to ingest and scans \cite{sen2013benchmarking}.
%The next step past ingesting and scanning is computing---running enrichment, algorithms and analytics.

NoSQL databases %such as Apache Accumulo
concentrate on high performance ingest and scans~\cite{sen2013benchmarking}. 
While ingests and scans solve some big data problems,
more complex analytics involve running tasks
such as enrichment, algorithms and analytics. These techniques
often move data from a database or storage engine to a
computational element. The ability to
perform enrichment, algorithms or analytics directly in a database or
storage engine can provide benefits such as \emph{selective access},
\emph{data locality} and \emph{infrastructure reuse}. 

Consider the popular Apache Accumulo database whose features as a database enable
fast access to data subsets and queries along indexed attributes. 
% Conducting computation within a database like Accumulo offers several advantages,
% assuming we can efficiently map it to the database's programming model:
% %as opposed to YARN or MapReduce directly on HDFS, are 
Accumulo sits atop the physical location data is stored and cached, 
such that computation inside Accumulo can avoid unnecessary network transfers,
effectively moving ``compute to data'' like a stored procedure
in contrast to client-server models that move ``data to compute.''
Computing within Accumulo also reuses its distributed infrastructure, 
such as write-ahead logging, fault-tolerant execution atop Zookeeper and 
horizontal scalability from a master load balancing tablets.

%cite linear algebra on database data?
Linear algebraic kernels form a basis for some of the most common
computational kernels applied to large scale data. 
Researchers in the GraphBLAS Forum \cite{mattson2014standards} have identified a set of primitive operations 
that form a basis for linear algebraic algorithms useful for graphs, including 
Sparse General Matrix Multiplication (SpGEMM),  Sparse Element-wise Multiplication (SpEWiseX),
Sparse Reference of a subset (SpRef), Reduction along a dimension (Reduce),
Function application (Apply) and others.
This article presents Graphulo, an effort to realize the GraphBLAS primitives 
and enable algorithms in the language of linear algebra server-side in Accumulo \cite{gadepally2015gabb}.

%I don't want to make something like MapReduce-- Accumulo facilitates a particular kind of computation 
%using iterators.  Not all computation patterns fit into the iterator framework. EXAMPLE
%We shouldn't stuff computation contradictory to the iterator framework into Accumulo, 
%as many have done stretching iterative algorithms into the MapReduce framework.

In this paper we focus on implementing SpGEMM, a core kernel at the
heart of the GraphBLAS.
In fact, many other GraphBLAS primitives can be expressed in terms of
SpGEMM through custom functions. 
SpGEMM usage ranges from graph search \cite{kepner2011graph} to table joins \cite{cohen2009mad} 
and plenty others described in the introduction of \cite{bulucc2010highly}.

We call our implementation of SpGEMM on Accumulo \textsc{TableMult}, short for multiplication of Accumulo tables.
Accumulo tables have many similarities to sparse matrices, though a more precise analogy is with Associative Arrays 
\cite{kepner2014gabb}. For the purpose of this work, we concentrate on
large distributed tables that may not fit in memory and use a streaming
approach that can distribute with Accumulo's infrastructure.
% Because Accumulo tables may span Hadoop clusters,
% we never assume a table fits in memory
% and instead take a streaming approach that distributes with Accumulo's infrastructure.

We are particularly interested in SpGEMM for queued analytics, that is, analytics on a selected table subset.  
Queued analytics allow us to maximally take advantage of Accumulo as a database 
by quickly accessing subsets of interest, 
whereas whole-table analytics usually perform better on parallel file systems such as Lustre or Hadoop.
We therefore prioritize low latency over high throughput, %when we must choose between them
in the best case enabling analysts to manipulate Accumulo data interactively.

%\subsection{Paper Outline}

We review iterator stacks, Accumulo's model of server-side computation, in Section~\ref{sAccumuloIterators}.
We formally define matrix multiplication and compare inner and outer product SpGEMM mehtods
in Section~\ref{sMatMul}, ultimately settling on outer product for our TableMult implementation.
We show TableMult's design as Accumulo iterators in Section~\ref{sTableMult},
and we test its scalability with experiments in Section~\ref{sPerformance}.
We conclude with a discussion on design alternatives in Section~\ref{sDiscussion}.

%Background and Algorithms
%Primer


%\section{Background}
%\label{sBackground}




\subsection{Primer: Accumulo Iterators}
\label{sAccumuloIterators}
Accumulo's server-side programming model is the %includes a mechanism to perform limited serer-side computation called the 
\emph{iterator stack}, a list of objects that implement the \texttt{SortedKeyValueIterator} (SKVI) interface.
At a high level, the iterator stack is a collection of datastreams originating
at Accumulo's data sources (Hadoop RFiles and cached in-memory maps), converging together in merge-sorts,
flowing through each of the stack's iterators and at the end, transferring to the client over the network.
Each iterator performs some operation on the stream along the way such as filtering out entries that
fail a filter function, all while maintaining data emission in sorted order.

Developers add custom logic for server-side computation
by creating new SKVIs and plugging them into an appropriate position in the iterator stack datastream.
In return for fitting their computation in the SKVI paradigm, developers gain
distributed parallelism for free as Accumulo runs the iterator stack on every relevant tablet simultaneously.

%The key idea behind our TableMult iterators is that instead of processing entries normally---transforming,
%reducing or expanding data flow through the stack---we leverage the iterator stack as a distributed conduit

SKVIs are reminiscent of built-in Java iterators %from the \texttt{java.lang} package
in that they have methods to return a current entry (\texttt{getTopKey} and \texttt{getTopValue})
and proceed to the next entry (\texttt{next}) until no more entries remain (\texttt{hasTop}).
On the other hand, SKVIs have more power than iterators in that they may initalize state
inside an \texttt{init} method, to which Accumulo passes
options of the form \texttt{Map<String,String>} from the client,
and that SKVIs have a \texttt{seek} method that jumps to the beginning of a passed-in range. 
System SKVIs at the top of an iterator stack perform actual disk seeks.% and cache locations in memory when seeked.

During a scan, Accumulo constructs an iterator stack for each tablet whose keys overlap some portion 
of the scan range. These iterator stacks may run in parallel, and each is seeked to the range of 
keys in the current tablet, instersected with the scan range. When any call to the iterator stack 
returns, Accumulo may choose to destroy the iterator stack and later re-create it,
passing a new seek range starting at the last key returned from \texttt{getTopKey}, exclusive.
Accumulo does this when it needs to switch data sources (such as RFiles) after a compaction, 
when a client stops requesting data, or out of fairness to other concurrent scans.

Iterators do not have full lifecycle control in that there is no \texttt{close} method 
that allows an iterator to clean up its state before being destroyted. The only safe way for an 
iterator to use state requiring cleanup, such as opening a file or starting a thread,
is for the iterator to clean up its state before returning from a method call.
Ideas discussed in \cite{ACCUMULO-3751} may lax this restriction for future Accumulo versions.

%\1 Iterators are most commonly used for streaming computation in the sense that iterators
%should ideally run in a single pass over their source's data and not store too much state.
%\1 No lifecycle control.

Iterators are most commonly used for ``reduction'' operations, in the sense of transforming
or eliminating entries passing through.  The Accumulo community generally discourages ``generator'' iterators 
that emit new entries not present in the original data source, not because generator iterators are impossible 
but because they are easy to misuse and violate SKVI constraints by emitting entries out of order or 
relying on state that fails when Accumulo chooses to destroy and re-create an iterator stack between method calls.

