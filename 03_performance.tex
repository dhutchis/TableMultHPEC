%!TEX root = SpGEMM_Accumulo_HPEC.tex

\section{Performance}
\label{sPerformance}

We evaluate TableMult with two variants of an experiment. 
First we measure the rate of computation as problem size increases.
We define problem size as number of rows in random input graphs 
represented as adjacency tables
and rate of computation as number of partial products processed per second.
Second we repeat the experiment for a fixed size problem with all tables split into two tablets,
allowing Accumulo to scan and write to them in parallel.

%% We evalutate our TableMult implementation with a weak scaling experiment,
%% measuring rate of computation as problem size increases.
%% We define problem size as the number of nodes in random input graphs
%% and rate of computation as the number of partial products processed per second.  
%% We also perform the same tests when input and output tables
%% are split into two tablets each, which allows Accumulo to scan and write to them in parallel.

%Ideally we would include run our tests on more than two tablets to truly test strong scaling, 
%but such tests are infeasible given the laptop's capabilities.

We compare Graphulo TableMult performance to D4M as a baseline because 
a user with one client machine's best alternative is reading input graphs from Accumulo, 
multiplying them at the client, and inserting the result back into Accumulo.

D4M stores tables as Associative Array objects in Matlab.  
Because Assoc Array multplication runs fast in memory, 
D4M bottlenecks on reading data from Accumulo and especially on writing back results.
We consequently expect TableMult to outperform D4M 
because TableMult avoids transferring data out of Accumulo for processing. 

We also expect TableMult to succeed on larger graph sizes than D4M because TableMult
uses a streaming outer product algorithm that does not store input tables in memory.
An alternative D4M implementation would mirror TableMult's streaming outer product algorithm,
enabling D4M to run on larger problem sizes at potentially worse performance.
We therefore imagine the whole-table D4M algorithm as an upper bound on the best performance 
achievable when multiplying Accumulo tables outside Accumulo's infrastructure.

We use the Graph500 unpermuted power law graph generator \cite{bader2006designing} 
to create random input tables,
 %also used in 100M insert/sec paper
such that the first row has high degree (number of columns) 
%The generator creates graphs with a power law structure, such that the first vertex has high degree
and subsequent rows exponentially decrease in degree.
The generator takes SCALE and EdgesPerVertex parameters, creating graphs with 2\textsuperscript{SCALE} 
rows and EdgesPerVertex $\times$ 2\textsuperscript{SCALE} entries.
We fix EdgesPerVertex to 16 and use SCALE to vary problem size. 

%We multiply the transpose of the first table with the second table in our tests.
The following procedure outlines our performance experiment for a given SCALE and either one or two tablets.
\begin{enumerate}
\item Generate two graphs with different random seeds and insert them into Accumulo as adjacency tables via D4M.
\item In the case of two tablets, identify an optimal split point for each input graph
and set the input graphs' table splits equal to that point.
``Optimal'' here means a split point that evenly divides an input graph into two tablets.
\item \label{ePreSplit1} Create an empty output table. For two tablets, pre-split it with 
an optimal input split position recorded from a previous multiplication run.
%% the first input table's split.
%% The split will not be optimal for the output table because the matrix product has a different degree distribution 
%% than that of the input tables, but it is close enough for the purposes of our test.
\item \label{ePreSplit1Compact} Compact the input and output tables 
so that Accumulo redistributes the tables' entries into the assigned tablets.
\item Run and time Graphulo TableMult multiplying the transpose of the first input table with the second.
\item Create, pre-split and compact a new result table for the D4M comparison 
as in step~\ref{ePreSplit1} and~\ref{ePreSplit1Compact}.
\item Run and time the D4M equivalent of TableMult:
 \begin{enumerate}
 \item Scan both input tables into D4M Associative Array objects in Matlab memory.
 \item Convert the string values from Accumulo into numeric values for each Assoc.
 \item Multiply the transpose of the first Assoc with the second Assoc.
 \item Convert the result Assoc back to String values and insert them into Accumulo.
 \end{enumerate}
\end{enumerate}

%\subsection{Environment}
We conduct the experiments on a laptop with 16GB RAM with dual dual-core Intel i7 processors %at 3GHz
running Ubuntu 14.04 linux. We use single-instance Accumulo 1.6.1, Hadoop 2.6.0 and ZooKeeper 3.4.6.
We allocate 2GB of memory to the Accumulo tablet server initially
(allowing growth in 500MB steps),
1GB for native in-memory maps and 256MB for data and index caches.


We chose not to use more than two tablets per table because more threads would run
than the laptop could handle.  Each additional tablet can potentially add the following threads:
\begin{enumerate}
\item Table $\matr{A}^\tr$ server-side scan thread
\item Table $\matr{A}^\tr$ client-side scan thread,

$\quad$ running from RemoteSourceIterator
\item Table $\matr{B}$ server-side scan/multiply thread,

$\quad$ running a TableMult iterator stack
\item Table $\matr{B}$ client-side scan thread, 

$\quad$ running from the initiating client; mostly idle
\item Table $\matr{C}$ server-side write thread
\item Table $\matr{C}$ client-side write thread,

$\quad$ running from RemoteWriteIterator
\item Table $\matr{C}$ server-side minor compaction threads,

$\quad$ running with a Combiner implementing $\oplus$
\end{enumerate}

\begin{figure}[tbh]
%\vspace{-6pt}
\centering
\includegraphics[width=\linewidth]{TableMultRate}
\caption{TableMult Processing Rate vs. Input Table Size}
\label{fTableMultPerf}
\vspace{-4pt}
\end{figure}

We show table $\matr{C}$ sizes and experiment timings in Table~\ref{tResultsParams}
and plot them in Figure~\ref{fTableMultPerf}.
We could not run the D4M comparison past SCALE 15 because $\matr{C}$ does not fit in memory.

For the scaled problem, the best results we could achieve are flat horizontal lines, 
indicating that we maintain the same level of operations per second as problem size increases.
%Graphulo roughly achieves weak scaling, although the two-tablet Graphulo curve shows instability.

One reason we see a downward rate trend at larger problem sizes is that Accumulo
needs to minor compact table $\matr{C}$ in the middle of a TableMult. 
The compactions trigger flushes to disk along with 
the $\oplus$ Combiner that sums partial products written to $\matr{C}$ so far, 
neither of which we include 
in rate measurements. % (in partial products per second).
%% Thus, one explanation for the rate decrease is that 
%% our rate measurements (in partial products per second) do not include summing 
%% and disk flush operations Accumulo performs during minor compaction.

For the fixed size problem, the best results we could achieve are two-tablet rates
double the one-tablet rates for every problem size.
Our experiment shows that Graphulo two-tablet multiply rates perform up to 1.5x better
than one-tablet rates with degraded performance at higher SCALEs.  
We attribute TableMult's shortfall to high processor contention for the four cores as a result of 
the 14 threads that may run concurrently with two tablets on ; in fact,
processor usage hovered near 100\% for all four laptop cores throughout the two-tablet experiments.
We expect better scaling when running our experiment 
in a larger Accumulo cluster that can handle more degrees of parallelism.

%Odd factor: OS frequently killed the Accumulo garbage collector.
